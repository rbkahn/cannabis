{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "UsageError: Line magic function `%` not found.\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "import urllib\n",
    "import requests\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "#from yanytapi import SearchAPI\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "#from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "#api = SearchAPI(\"TjGk9kxFO9ScvfSF8AfeqkXjjujBnz6e\")\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(years=None):\n",
    "    if not years:\n",
    "        return pd.concat([pd.read_csv('articles/' + file) for file in os.listdir('articles') if 'articles' in file], ignore_index=True, sort=False)\n",
    "    else:\n",
    "        return pd.concat([pd.read_csv('articles/' + csv_name(year)) for year in years], ignore_index=True, sort=False)\n",
    "\n",
    "def get_sentence_list(years=None, only_weed=False):\n",
    "    df = get_df(years=years)\n",
    "    df['text'] = df['text'].map(process_strings)\n",
    "    df['text'] = df['text'].map(remove_stopwords)\n",
    "    if only_weed:\n",
    "        return [remove_waste(p.split()) for p in df['text'] if 'marijuana' in p or 'cannabis' in p]\n",
    "    else:\n",
    "        return [remove_waste(p.split()) for p in df['text']]\n",
    "\n",
    "def get_list(years=None, only_weed=False):\n",
    "    return [item for sublist in get_sentence_list(years, only_weed) for item in sublist]\n",
    "\n",
    "def get_sentence(years=None):\n",
    "    split_it = get_list(years)\n",
    "    return ' '.join(split_it)\n",
    "\n",
    "def process(text):\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def process_strings(s):\n",
    "    s = s.lower()\n",
    "    s = s.replace(\"’\",\"'\")\n",
    "    s = s.replace(\"'s\",\"\")\n",
    "    bad_chars = \".;:''?!,\\[]”“()\\\"\"\n",
    "    for char in bad_chars:\n",
    "        s = s.replace(char, \"\")\n",
    "    if len(s) > 0 and s[0] == '$':\n",
    "        return '$'\n",
    "    return s\n",
    "    \n",
    "def csv_name(year):\n",
    "    return 'articles-' + str(year) + '.csv'\n",
    "\n",
    "def remove_waste(sentence):\n",
    "    wasted_words = ['—', '&', '-']\n",
    "    return [word for word in sentence if word not in wasted_words]\n",
    "\n",
    "def clean_data(df, verbose=True):\n",
    "    #df['date'] = pd.to_datetime(df['date'], utc=True).dt.date\n",
    "    df['date'] = df['date'].apply(lambda s : s[:10])\n",
    "    df.drop([col for col in df.columns if 'Unnamed' in col], axis=1, inplace=True)\n",
    "    if verbose:\n",
    "        print(\"Original shape: \", df.shape)\n",
    "    df.drop(df.loc[df['text'] == \"We’re sorry, we seem to have lost this page, but we don’t want to lose you.\"].index, inplace=True)\n",
    "    df.drop(df.loc[df['text'] == \"We’re sorry, we seem to have lost this page, but we don’t want to lose you. Report the broken link here.\"].index, inplace=True)\n",
    "    df.drop(df.loc[df['text'] == \"Go to Home Page »\"].index, inplace=True)\n",
    "    if verbose:\n",
    "        print(\"Dropped failed pages: \", df.shape)\n",
    "    df.drop(df.loc[(df['text'].str.startswith('Compiled by ')) & (df['p#'] == 1.0)].index, inplace=True)\n",
    "    df.drop(df.loc[(df['text'].str.startswith('By ')) & (df['p#'] == 1.0)].index, inplace=True)\n",
    "    if verbose:\n",
    "        print(\"Dropped byline paragraphs: \", df.shape)\n",
    "    df['text'] = df['text'].apply(lambda x : x.replace(\"\\n\", \"\"))\n",
    "    df['text'] = df['text'].apply(lambda x : ' '.join(x.split()))\n",
    "    df.drop_duplicates(subset=['date', 'title', 'text', 'p#'], inplace=True)\n",
    "    if verbose:\n",
    "        print(\"Dropped duplicates: \", df.shape)\n",
    "    return df\n",
    "\n",
    "def get_summary():\n",
    "    l = list()\n",
    "    for year in range(1980, 2020):\n",
    "        df = clean_data(get_df(years=((year,))), verbose=False)\n",
    "            l.append({'year': year, 'articles': len(df['id'].unique()), 'tokens' : len(' '.join(df['text']))})\n",
    "    return pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "19487\n"
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1b5e88ae5b88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1980\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2020\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_paragraphs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, list found"
     ]
    }
   ],
   "source": [
    "from vec_utils import process_paragraphs, get_df\n",
    "df = get_df(range(1980, 2020))\n",
    "print(len(df['id'].unique()))\n",
    "ps = process_paragraphs(df)\n",
    "words = 0\n",
    "for k in range(len(ps)):\n",
    "    words += len(ps[k])\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "people 985.0\nmr 1055.0\nstates 1082.0\nstate 1103.0\nrecreational 1106.0\nlegal 1116.0\nsaid 1884.0\nuse 1930.0\nmedical 2506.0\ncannabis 3624.0\n"
    }
   ],
   "source": [
    "years = range(2010, 2020)\n",
    "with open(get_vocab_name(years), \"r\") as text_file:\n",
    "    vocab = text_file.readlines()\n",
    "for i in range(len(vocab)):\n",
    "    vocab[i] = vocab[i][:-1]\n",
    "co_matrix = np.loadtxt(get_matrix_name(years))\n",
    "backward_vocab = {vocab[n] : n for n in range(len(vocab))}\n",
    "mar = backward_vocab['marijuana']\n",
    "can = backward_vocab['cannabis']\n",
    "top_ten = sorted(vocab, key=lambda word : co_matrix[mar][backward_vocab[word]]+co_matrix[can][backward_vocab[word]])[-11:-1]\n",
    "for word in top_ten:\n",
    "    print(word, co_matrix[mar][backward_vocab[word]]+co_matrix[can][backward_vocab[word]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{'original': None, 'person': [], 'organization': None}\nMedical Marijuana, Pro and Con2006-04-26\n0 Advertisement\n1 APRIL 26, 2006\n\n2 To the Editor:\n3 It is no surprise that the Food and Drug Administration dismissed the medical value of cannabis. Plants cannot be patented.\n4 An agency with such close ties to the pharmaceutical industry has no incentive to recognize the medical value of a plant that people could grow themselves free of charge.\n5 Kenneth Michael White  Ontario, Calif., April 21, 2006\n6 The writer is the author of \"The Beginning of Today: The Marihuana Tax Act of 1937.\"\n7 We are continually improving the quality of our text archives. Please send feedback, error reports,\n        and suggestions to archive_feedback@nytimes.com.\n8 A version of this letter appears in print on April 26, 2006, on Page A00018 of the National edition with the headline: Medical Marijuana, Pro and Con.  Today's Paper|Subscribe\n\n\n9 Go to Home Page »\n"
    }
   ],
   "source": [
    "articles = api.search('Medical Marijuana, Pro and Con', begin_date='20060426', end_date='20060426')\n",
    "for article in articles:\n",
    "    print(article.byline)\n",
    "    print(get_identifier(article))\n",
    "    session = requests\n",
    "    url = article.web_url\n",
    "    req = session.get(url)\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    count = 0\n",
    "    for p in paragraphs:\n",
    "        print(count, p.get_text())\n",
    "        count += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifier(article):\n",
    "    return process(article.headline['main']) + str(pd.to_datetime(article.pub_date)).split(' ')[0]\n",
    "def get_identifier_set(df):\n",
    "    return set(df['title'] + df['date'])\n",
    "df = clean_data(get_df(), verbose=False)\n",
    "check_set = get_identifier_set(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "date                                                 id   p#  \\\n60270  2001-12-15  nyt://article/d42d0908-f405-58ce-9844-7bee522b...  1.0   \n\n                                                    text  \\\n60270  Research on the medical uses of marijuana is s...   \n\n                                                  title  \\\n60270  After Two-Decade Halt, Marijuana Research Is Set   \n\n                                                     url  \n60270  https://www.nytimes.com/2001/12/15/us/after-tw...  \n"
    }
   ],
   "source": [
    "articles = api.search(\"marijuana\", begin_date='20011101', end_date='20011231')\n",
    "\n",
    "for article in articles:\n",
    "    print(df.loc[(df['title'] == process(article.headline['main'])) & \\\n",
    "                                    (df['date'] ==  article.pub_date[:10]) & \\\n",
    "                                   (df['p#'] == 1.0)])\n",
    "    break\n",
    "    print(\"Actually, already read \", article.headline['main'])\n",
    "    print(article.headline['main'])\n",
    "    print(article.pub_date)\n",
    "    continue\n",
    "    session = requests\n",
    "    url = article.web_url\n",
    "    req = session.get(url)\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>id</th>\n      <th>p#</th>\n      <th>text</th>\n      <th>title</th>\n      <th>url</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>",
      "text/plain": "Empty DataFrame\nColumns: [date, id, p#, text, title, url]\nIndex: []"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['title'] == process('New Drug Czar, Old Problem')) & \\\n",
    "                                    ((df['date'] ==  '2001-05-12T05:00:00+0000'[:10]) & \\\n",
    "                                   (df['p#'] == 1.0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>id</th>\n      <th>p#</th>\n      <th>text</th>\n      <th>title</th>\n      <th>url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>421858</th>\n      <td>2019-02-02</td>\n      <td>nyt://article/82d6002c-0edc-56a0-a209-27c56a31...</td>\n      <td>1.0</td>\n      <td>Last September, a group of academics and activ...</td>\n      <td>He Committed Murder. Then He Graduated From an...</td>\n      <td>https://www.nytimes.com/2019/02/02/business/br...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "              date                                                 id   p#  \\\n421858  2019-02-02  nyt://article/82d6002c-0edc-56a0-a209-27c56a31...  1.0   \n\n                                                     text  \\\n421858  Last September, a group of academics and activ...   \n\n                                                    title  \\\n421858  He Committed Murder. Then He Graduated From an...   \n\n                                                      url  \n421858  https://www.nytimes.com/2019/02/02/business/br...  "
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['p#'] == 1.0) & (df['date'] ==  '2019-02-02T05:00:00+0000'[:10]) & (df['title'] == 'He Committed Murder. Then He Graduated From an Elite Law School. Would You Hire Him as Your Attorney?')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'He Committed Murder. Then He Graduated From an Elite Law School. Would You Hire Him as Your Attorney?'"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['p#'] == 1.0) & (df['date'] ==  '2019-02-02T05:00:00+0000'[:10])]['title'][421858]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0         1985-12-26\n1         1985-12-26\n2         1985-12-26\n3         1985-12-26\n4         1985-12-26\n5         1985-12-26\n6         1985-12-26\n7         1985-12-26\n8         1985-12-26\n9         1985-12-26\n10        1985-12-26\n11        1985-12-26\n12        1985-12-26\n13        1985-12-26\n14        1985-12-26\n15        1985-12-26\n16        1985-12-26\n17        1985-12-26\n18        1985-12-26\n19        1985-12-24\n20        1985-12-24\n21        1985-12-24\n22        1985-12-24\n23        1985-12-24\n24        1985-12-24\n25        1985-12-24\n26        1985-12-24\n27        1985-12-22\n28        1985-12-22\n29        1985-12-22\n             ...    \n421901    2019-02-02\n421902    2019-02-02\n421903    2019-02-02\n421904    2019-02-02\n421905    2019-02-02\n421906    2019-02-02\n421907    2019-02-02\n421908    2019-02-02\n421909    2019-02-02\n421910    2019-02-02\n421911    2019-02-02\n421912    2019-02-02\n421913    2019-02-02\n421914    2019-02-02\n421915    2019-02-02\n421916    2019-02-02\n421917    2019-02-02\n421918    2019-02-02\n421919    2019-02-02\n421920    2019-02-02\n421921    2019-02-02\n421922    2019-02-02\n421923    2019-02-02\n421924    2019-02-02\n421925    2019-02-02\n421926    2019-02-02\n421927    2019-02-02\n421928    2019-02-02\n421929    2019-01-19\n421930    2019-01-19\nName: date, Length: 390865, dtype: object"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'].apply(lambda x : x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>articles</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1980</td>\n      <td>248</td>\n      <td>80969</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1981</td>\n      <td>369</td>\n      <td>1983291</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1982</td>\n      <td>336</td>\n      <td>1627674</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1983</td>\n      <td>313</td>\n      <td>1591410</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1984</td>\n      <td>332</td>\n      <td>1856424</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1985</td>\n      <td>360</td>\n      <td>1875560</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1986</td>\n      <td>501</td>\n      <td>2842728</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1987</td>\n      <td>430</td>\n      <td>2413639</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1988</td>\n      <td>379</td>\n      <td>2369749</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1989</td>\n      <td>357</td>\n      <td>2060262</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1990</td>\n      <td>318</td>\n      <td>1756442</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>1991</td>\n      <td>239</td>\n      <td>1304803</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>1992</td>\n      <td>295</td>\n      <td>1907123</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>1993</td>\n      <td>250</td>\n      <td>1689191</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>1994</td>\n      <td>294</td>\n      <td>2037271</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>1995</td>\n      <td>314</td>\n      <td>1822227</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>1996</td>\n      <td>466</td>\n      <td>2567095</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1997</td>\n      <td>469</td>\n      <td>2942600</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1998</td>\n      <td>407</td>\n      <td>2336014</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1999</td>\n      <td>392</td>\n      <td>3339559</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2000</td>\n      <td>497</td>\n      <td>3275862</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>2001</td>\n      <td>463</td>\n      <td>3724687</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>2002</td>\n      <td>494</td>\n      <td>3517595</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>2003</td>\n      <td>418</td>\n      <td>2630237</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>2004</td>\n      <td>454</td>\n      <td>3492901</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>2005</td>\n      <td>523</td>\n      <td>3576341</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>2006</td>\n      <td>800</td>\n      <td>5578207</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>2007</td>\n      <td>1392</td>\n      <td>9853736</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>2008</td>\n      <td>636</td>\n      <td>4930158</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>2009</td>\n      <td>580</td>\n      <td>5227332</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2010</td>\n      <td>577</td>\n      <td>4782590</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>2011</td>\n      <td>427</td>\n      <td>3010170</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>2012</td>\n      <td>521</td>\n      <td>3605416</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>2013</td>\n      <td>564</td>\n      <td>3797123</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>2014</td>\n      <td>821</td>\n      <td>5372714</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>2015</td>\n      <td>719</td>\n      <td>5722493</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>2016</td>\n      <td>686</td>\n      <td>5620534</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>2017</td>\n      <td>601</td>\n      <td>4586933</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>2018</td>\n      <td>966</td>\n      <td>7673921</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>2019</td>\n      <td>841</td>\n      <td>6968804</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    year  articles   tokens\n0   1980       248    80969\n1   1981       369  1983291\n2   1982       336  1627674\n3   1983       313  1591410\n4   1984       332  1856424\n5   1985       360  1875560\n6   1986       501  2842728\n7   1987       430  2413639\n8   1988       379  2369749\n9   1989       357  2060262\n10  1990       318  1756442\n11  1991       239  1304803\n12  1992       295  1907123\n13  1993       250  1689191\n14  1994       294  2037271\n15  1995       314  1822227\n16  1996       466  2567095\n17  1997       469  2942600\n18  1998       407  2336014\n19  1999       392  3339559\n20  2000       497  3275862\n21  2001       463  3724687\n22  2002       494  3517595\n23  2003       418  2630237\n24  2004       454  3492901\n25  2005       523  3576341\n26  2006       800  5578207\n27  2007      1392  9853736\n28  2008       636  4930158\n29  2009       580  5227332\n30  2010       577  4782590\n31  2011       427  3010170\n32  2012       521  3605416\n33  2013       564  3797123\n34  2014       821  5372714\n35  2015       719  5722493\n36  2016       686  5620534\n37  2017       601  4586933\n38  2018       966  7673921\n39  2019       841  6968804"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}