{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "import urllib\n",
    "import requests\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "from yanytapi import SearchAPI\n",
    "from gensim.similarities.index import AnnoyIndexer\n",
    "from gensim.models import Word2Vec\n",
    "from mittens import GloVe, Mittens\n",
    "from gensim.matutils import corpus2csc\n",
    "from gensim.corpora import Dictionary\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "#api = SearchAPI(\"TjGk9kxFO9ScvfSF8AfeqkXjjujBnz6e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_strings(s):\n",
    "    s = s.lower().replace(\".\", \"\").replace(\"'s\",\"\").replace(\"?\",\"\").replace(\"!\",\"\").replace(\",\", \"\").replace(\";\", \"\").replace(\"\\\"\", \"\").replace(\"”\", \"\").replace(\"“\", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    if len(s) > 0 and s[0] == '$':\n",
    "        return '$'\n",
    "    return s\n",
    "    \n",
    "def csv_name(year):\n",
    "    return 'articles-' + str(year) + '.csv'\n",
    "\n",
    "def remove_waste(sentence):\n",
    "    wasted_words = ['—', '&']\n",
    "    return [word for word in sentence if word not in wasted_words]\n",
    "\n",
    "def co_occurrence(df, window=5):\n",
    "    print(\"co-occurrence\")\n",
    "    sentences = [remove_waste(list(map(lambda s : process_strings(s), p.split()))) for p in df['text']]\n",
    "    d = dict()\n",
    "    for sentence in sentences:\n",
    "        for i in range(len(sentence)):\n",
    "            if sentence[i] not in d:\n",
    "                d[sentence[i]] = defaultdict(int)\n",
    "            for j in range(-window, window):\n",
    "                if i+j >= 0 and i+j < len(sentence) and i != j: \n",
    "                    d[sentence[i]][sentence[i+j]] += 1\n",
    "    return d\n",
    "\n",
    "def trim_d(d):\n",
    "    print(\"trimming\")\n",
    "    vocab = list(d.keys())\n",
    "    print(len(vocab))\n",
    "    for word in d:\n",
    "        if sum([v for k, v in dict(d[word]).items()]) < 100:\n",
    "            vocab.remove(word)\n",
    "    print(len(vocab))\n",
    "    return {k:d[k] for k in vocab}\n",
    "\n",
    "def d_to_matrix(d):\n",
    "    print(\"matrixing\")\n",
    "    vocab = list(d.keys())\n",
    "    matrix = np.zeros((len(vocab), len(vocab)))\n",
    "    for i in range(len(vocab)):\n",
    "        for j in range(len(vocab)):\n",
    "            matrix[i][j] = d[vocab[i]][vocab[j]]\n",
    "    return vocab, matrix\n",
    "\n",
    "def generate_embeddings(df):\n",
    "    d = co_occurrence(df)\n",
    "    trimmed = trim_d(d)\n",
    "    vocab, cooccurrence = d_to_matrix(d)\n",
    "    glove_model = GloVe(n=25, max_iter=100)\n",
    "    embeddings = glove_model.fit(cooccurrence)\n",
    "    return vocab, embeddings\n",
    "\n",
    "def glove2dict(glove_filename):\n",
    "    with open(glove_filename, encoding=\"utf8\") as f:\n",
    "        reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
    "        embed = {line[0]: np.array(list(map(float, line[1:])))\n",
    "                for line in reader}\n",
    "    return embed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co-occurrence\n",
      "trimming\n",
      "90557\n",
      "15798\n",
      "matrixing\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([pd.read_csv(csv_name(year)) for year in [2019, 2018, 2017]], ignore_index=True, sort=False)\n",
    "d = co_occurrence(df)\n",
    "d = trim_d(d)\n",
    "vocab, cooccurrence = d_to_matrix(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded original embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 50: error 65069.52721"
     ]
    }
   ],
   "source": [
    "original_embedding = glove2dict('./glove.6B/glove.6B.50d.txt')\n",
    "print(\"loaded original embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mittens_model = Mittens(n=50, max_iter=1000)\n",
    "# Note: n must match the original embedding dimension\n",
    "new_embeddings = mittens_model.fit(\n",
    "    cooccurrence,\n",
    "    vocab=vocab,\n",
    "    initial_embedding_dict=original_embedding)\n",
    "np.savetxt('embeddings.csv', new_embeddings, delimiter=',')\n",
    "with open(\"vocab.txt\", \"wb\") as fp:\n",
    "    pickle.dump(vocab, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2010s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=28697, size=100, alpha=0.025)\n",
      "[('marijuana', 1.0), ('cannabis', 0.7156508564949036), ('drug:', 0.6136324107646942), ('recreational', 0.5932257771492004), ('hemp', 0.5360226631164551), ('tobacco', 0.5102111399173737), ('juul', 0.4959568381309509)]\n",
      "[('cannabis', 1.0), ('marijuana', 0.715650886297226), ('hemp', 0.677280455827713), ('drug:', 0.6450612246990204), ('tobacco', 0.6384859085083008), ('e-cigarette', 0.6166323721408844), ('recreational', 0.5828753709793091)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([pd.read_csv(csv_name(year)) for year in [2019, 2018, 2017]], ignore_index=True, sort=False)\n",
    "sentences = [list(map(lambda s : process_strings(s), p.split())) for p in df['text']]\n",
    "model = Word2Vec(sentences)\n",
    "print(model)\n",
    "words = list(model.wv.vocab)\n",
    "indexer = AnnoyIndexer(model, 2)\n",
    "print(model.most_similar(\"marijuana\", topn=7, indexer=indexer))\n",
    "print(model.most_similar(\"cannabis\", topn=7, indexer=indexer))\n",
    "X = model.wv[model.wv.vocab]\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2000s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=21731, size=100, alpha=0.025)\n",
      "[('marijuana', 0.9998779296875), ('drugs', 0.6875728666782379), ('drug', 0.6553664803504944), ('heroin', 0.6443754732608795), ('cannabis', 0.6303356289863586), ('cocaine', 0.6300118863582611), ('driving', 0.5520328283309937)]\n",
      "[('cannabis', 0.9998273665260058), ('tobacco', 0.7496159970760345), ('pot', 0.7131913900375366), ('alcohol', 0.7042410373687744), ('industry', 0.704172283411026), ('substances', 0.6968700587749481), ('amount', 0.6866689622402191)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([pd.read_csv(csv_name(year)) for year in [2009, 2008, 2007]], ignore_index=True, sort=False)\n",
    "sentences = [list(map(lambda s : process_strings(s), p.split())) for p in df['text']]\n",
    "model = Word2Vec(sentences)\n",
    "print(model)\n",
    "words = list(model.wv.vocab)\n",
    "indexer = AnnoyIndexer(model, 2)\n",
    "print(model.most_similar(\"marijuana\", topn=7, indexer=indexer))\n",
    "print(model.most_similar(\"cannabis\", topn=7, indexer=indexer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1990s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=16479, size=100, alpha=0.025)\n",
      "[('marijuana', 1.0), ('drugs', 0.7386797070503235), ('crack', 0.717893123626709), ('drug', 0.6608239114284515), ('use', 0.5833125710487366), ('hemp', 0.5457489788532257), ('treatment', 0.5431174635887146)]\n",
      "[('cannabis', 1.0), ('campaigns', 0.82892145216465), ('dependence', 0.8200516849756241), ('increasing', 0.8163576722145081), ('ncadd', 0.8004484325647354), ('nuclear', 0.7999800741672516), ('stem', 0.7927206009626389)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([pd.read_csv(csv_name(year)) for year in [1999, 1998, 1997]], ignore_index=True, sort=False)\n",
    "sentences = [list(map(lambda s : process_strings(s), p.split())) for p in df['text']]\n",
    "model = Word2Vec(sentences)\n",
    "print(model)\n",
    "words = list(model.wv.vocab)\n",
    "indexer = AnnoyIndexer(model, 2)\n",
    "print(model.most_similar(\"marijuana\", topn=7, indexer=indexer))\n",
    "print(model.most_similar(\"cannabis\", topn=7, indexer=indexer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1980s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=14386, size=100, alpha=0.025)\n",
      "[('marijuana', 1.0), ('cocaine', 0.8171534389257431), ('heroin', 0.7011248171329498), ('drugs', 0.6981644332408905), ('drug', 0.5899725556373596), ('amount', 0.589265763759613), ('used', 0.5826479196548462)]\n",
      "[('cannabis', 0.9998273665260058), ('sympathy', 0.8064617663621902), ('pot', 0.7917799055576324), ('fix', 0.7758041322231293), ('types', 0.7744040936231613), ('mexicans', 0.7726016491651535), ('institutions', 0.7704524546861649)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([pd.read_csv(csv_name(year)) for year in [1989, 1988, 1987]], ignore_index=True, sort=False)\n",
    "sentences = [list(map(lambda s : process_strings(s), p.split())) for p in df['text']]\n",
    "model = Word2Vec(sentences)\n",
    "print(model)\n",
    "words = list(model.wv.vocab)\n",
    "indexer = AnnoyIndexer(model, 2)\n",
    "print(model.most_similar(\"marijuana\", topn=7, indexer=indexer))\n",
    "print(model.most_similar(\"cannabis\", topn=7, indexer=indexer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'glove'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-ba9664e288bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mglove\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGlove\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Creating a corpus object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'glove'"
     ]
    }
   ],
   "source": [
    "from glove import Corpus, Glove\n",
    "\n",
    "#Creating a corpus object\n",
    "corpus = Corpus() \n",
    "\n",
    "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
    "corpus.fit(lines, window=10)\n",
    "\n",
    "glove = Glove(no_components=5, learning_rate=0.05) \n",
    "glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)\n",
    "glove.add_dictionary(corpus.dictionary)\n",
    "glove.save('glove.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
