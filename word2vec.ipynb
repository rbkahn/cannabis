{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "UsageError: Line magic function `%` not found.\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "import urllib\n",
    "import requests\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "from yanytapi import SearchAPI\n",
    "from gensim.similarities.index import AnnoyIndexer\n",
    "from gensim.models import Word2Vec\n",
    "from mittens import GloVe, Mittens\n",
    "from gensim.matutils import corpus2csc\n",
    "from gensim.corpora import Dictionary\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "#api = SearchAPI(\"TjGk9kxFO9ScvfSF8AfeqkXjjujBnz6e\")\n",
    "% matplotlib inline\n",
    "from gensim.test.utils import common_texts, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(years=None):\n",
    "    if not years:\n",
    "        return pd.concat([pd.read_csv('articles/' + file) for file in os.listdir('articles') if 'articles' in file], ignore_index=True, sort=False)\n",
    "    else:\n",
    "        return pd.concat([pd.read_csv('articles/' + csv_name(year)) for year in years], ignore_index=True, sort=False)\n",
    "\n",
    "def get_sentence_list(years=None, only_weed=False):\n",
    "    df = get_df(years=years)\n",
    "    df['text'] = df['text'].map(process_strings)\n",
    "    df['text'] = df['text'].map(remove_stopwords)\n",
    "    if only_weed:\n",
    "        paragraphs = [remove_waste(p.split()) for p in df['text'] if 'marijuana' in p or 'cannabis' in p]\n",
    "    else:\n",
    "        paragraphs = [remove_waste(p.split()) for p in df['text']]\n",
    "    return paragraphs\n",
    "\n",
    "def get_list(years=None, only_weed=False):\n",
    "    return [item for sublist in get_sentence_list(years, only_weed) for item in sublist]\n",
    "\n",
    "def get_sentence(years=None):\n",
    "    split_it = get_list(years)\n",
    "    return ' '.join(split_it)\n",
    "\n",
    "def process_strings(s):\n",
    "    s = s.lower()\n",
    "    s = s.replace(\"’\",\"'\")\n",
    "    s = s.replace(\"'s\",\"\")\n",
    "    bad_chars = \".;:''?!,\\[]”“()\\\"\"\n",
    "    for char in bad_chars:\n",
    "        s = s.replace(char, \"\")\n",
    "    if len(s) > 0 and s[0] == '$':\n",
    "        return '$'\n",
    "    return s\n",
    "    \n",
    "def csv_name(year):\n",
    "    return 'articles-' + str(year) + '.csv'\n",
    "\n",
    "def remove_waste(sentence):\n",
    "    wasted_words = ['—', '&', '-']\n",
    "    return [word for word in sentence if word not in wasted_words]\n",
    "\n",
    "def co_occurrence(df, window=5):\n",
    "    print(\"co-occurrence\")\n",
    "    sentences = [remove_waste(list(map(lambda s : process_strings(s), p.split()))) for p in df['text']]\n",
    "    d = dict()\n",
    "    for sentence in sentences:\n",
    "        for i in range(len(sentence)):\n",
    "            if sentence[i] not in d:\n",
    "                d[sentence[i]] = defaultdict(int)\n",
    "            for j in range(-window, window):\n",
    "                if i+j >= 0 and i+j < len(sentence) and i != j: \n",
    "                    d[sentence[i]][sentence[i+j]] += 1\n",
    "    return d\n",
    "\n",
    "def trim_d(d):\n",
    "    print(\"trimming\")\n",
    "    vocab = list(d.keys())\n",
    "    print(len(vocab))\n",
    "    for word in d:\n",
    "        if sum([v for k, v in dict(d[word]).items()]) < 100:\n",
    "            vocab.remove(word)\n",
    "    print(len(vocab))\n",
    "    return {k:d[k] for k in vocab}\n",
    "\n",
    "def d_to_matrix(d):\n",
    "    print(\"matrixing\")\n",
    "    vocab = list(d.keys())\n",
    "    matrix = np.zeros((len(vocab), len(vocab)))\n",
    "    for i in range(len(vocab)):\n",
    "        for j in range(len(vocab)):\n",
    "            matrix[i][j] = d[vocab[i]][vocab[j]]\n",
    "    return vocab, matrix\n",
    "\n",
    "def generate_embeddings(df):\n",
    "    d = co_occurrence(df)\n",
    "    trimmed = trim_d(d)\n",
    "    vocab, cooccurrence = d_to_matrix(d)\n",
    "    glove_model = GloVe(n=25, max_iter=100)\n",
    "    embeddings = glove_model.fit(cooccurrence)\n",
    "    return vocab, embeddings\n",
    "\n",
    "def glove2dict(glove_filename):\n",
    "    with open(glove_filename, encoding=\"utf8\") as f:\n",
    "        reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
    "        embed = {line[0]: np.array(list(map(float, line[1:])))\n",
    "                for line in reader}\n",
    "    return embed\n",
    "\n",
    "\n",
    "def display_closestwords_tsnescatterplot(model, word):\n",
    "    \n",
    "    arr = np.empty((0,100), dtype='f')\n",
    "    word_labels = [word]\n",
    "\n",
    "    # get close words\n",
    "    close_words = model.similar_by_word(word)\n",
    "    \n",
    "    # add the vector for each of the closest words to the array\n",
    "    arr = np.append(arr, np.array([model[word]]), axis=0)\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model[wrd_score[0]]\n",
    "        word_labels.append(wrd_score[0])\n",
    "        arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
    "        \n",
    "    # find tsne coords for 2 dimensions\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    Y = tsne.fit_transform(arr)\n",
    "\n",
    "    x_coords = Y[:, 0]\n",
    "    y_coords = Y[:, 1]\n",
    "    # display scatter plot\n",
    "    plt.scatter(x_coords, y_coords)\n",
    "\n",
    "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "    plt.xlim(x_coords.min()+0.00005, x_coords.max()+0.00005)\n",
    "    plt.ylim(y_coords.min()+0.00005, y_coords.max()+0.00005)\n",
    "    plt.show()\n",
    "\n",
    "def get_model_name(years):\n",
    "    return \"w2v_embeddings/%d-%d.model\" % (years[0], years[-1])\n",
    "\n",
    "def generate_w2v(years):\n",
    "    path = \"w2v_embeddings/%d-%d.model\" % (years[0], years[-1])\n",
    "    sentences = get_sentence_list(years=years)\n",
    "    model = Word2Vec(sentences,min_count=10)\n",
    "    model.save(path)\n",
    "\n",
    "def display_highlights(model):\n",
    "    if type(model) == range or type(model) == list:\n",
    "        model = Word2Vec.load(get_model_name(model))\n",
    "    words = list(model.wv.vocab)\n",
    "    indexer = AnnoyIndexer(model, 2)\n",
    "    print(model.wv.most_similar(\"marijuana\", topn=7, indexer=indexer))\n",
    "    print(model.wv.most_similar(\"cannabis\", topn=7, indexer=indexer))\n",
    "    display_closestwords_tsnescatterplot(model, \"marijuana\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2010s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = 'glove_embeddings/embeddings-00.csv'\n",
    "tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "glove2word2vec(glove_file, tmp_file)\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:133: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\index.py:184: FutureWarning: The default argument for metric will be removed in future version of Annoy. Please pass metric='angular' explicitly.\n  index = AnnoyIndex(num_features)\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:135: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'marijuana' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-1b409a5ebece>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplay_highlights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-ba6a6633c8e2>\u001b[0m in \u001b[0;36mdisplay_highlights\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAnnoyIndexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"marijuana\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannabis\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[0mdisplay_closestwords_tsnescatterplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"marijuana\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word 'marijuana' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "display_highlights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}